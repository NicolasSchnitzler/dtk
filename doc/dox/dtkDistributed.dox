/* dtk.dox ---
 *
 * Author: Nicolas Niclausse
 * Copyright (C) 2011 - Nicolas Niclausse, Inria.
 * Created: Sat Feb  6 14:33:47 2010 (+0100)
 * Version: $Id$
 * Last-Updated: ven. mai 11 17:22:31 2012 (+0200)
 *           By: Nicolas Niclausse
 *     Update #: 202
 */

/* Commentary:
 *
 */

/* Change log:
 *
 */

/*! \page dtkDistributed dtkDistributed Reference Documentation
\author Nicolas Niclausse <nicolas.niclausse@inria.fr>
\author Julien Wintz <julien.wintz@inria.fr>
\date September 2011

\section intro Introduction

There are 3 components in dtkDistributed architecture:
 - 1 controller: dtkDistributedController (typically runs on the workstations/laptop)
 - 1 server dtkDistributedServer (typically runs on the cluster frontend)
 - N slaves dtkDistributedSlave (typically runs on the cluster nodes)

The slaves can communicate with each others through MPI (using
dtkDistributedCommunicatorMpi) or TCP (using dtkDistributedCommunicatorTcp), but the
communications between the controller/slaves and the server is based on
TCP (using a dtkDistributedSocket object). There's no direct
communication between the controller and the slaves.

Currently, the server is able to take resources from OAR (see
dtkDistributedServerManagerOar),  Torque (see
dtkDistributedServerManagerTorque) or any remote host available
through SSH (it will detect the number of cores of the host automatically).

The server can be started by the controller (with the deploy method)
using ssh; setup for a given server can be specified into the dtk.conf file,
within the [distributed] group, like this:

@code
[distributed]
nef-devel.inria.fr_server_path=/home/nniclaus/git/dtk/build/bin/dtkDistributedTutorial5Server
nef-devel.inria.fr_server_type=torque
nef-devel.inria.fr_server_forward=false
@endcode

If forward is set to true, then a ssh tunnel will be used for
communications between the controller and the server (useful to bypass
firewalls).

To be able to run a slave with MPI, you can configure the mpirun
parameters in the [distributed] group:

@code
[distributed]
nef-devel.inria.fr_mpirun_path==/opt/openmpi-gcc/current/bin/mpirun
nef-devel.inria.fr_mpirun_args=" -x DISPLAY=:0.0 "
@endcode


\section protocol dtkDistributed protocol

dtkDistributed protocol is loosely based on HTTP. This is encapsulated
into the dtkDistributedMessage class.

\subsection status get the status of a cluster

the controller sends to the server:
@code
GET /status
content-size: 0
@endcode

and the server replies with:
@code
OK /status
content-size: <size>
content-type: json
<json>
@endcode

\subsection submit submit a job

the controller sends to the server:
@code
PUT /job
content-size: <size>
content-type: json
<json>
@endcode

and the server replies with:
@code
OK /job/<jobid>
content-size: 0
@endcode


\subsection endjob job ending

the slave sends to the server:
@code
ENDED /job/<jobid>
content-size: 0
@endcode

and the server forwards to the controller:
@code
ENDED /job/<jobid>
content-size: 0
@endcode


\subsection deljob delete a job

the controller sends to the server:
@code
DELETE /job/<jobid>
content-size: 0
@endcode

and the server forwards to the controller:
@code
OK|ERROR /deleted/job/<jobid>
content-size: <size>
[content-type: text
<error message>]
@endcode


\subsection rank set the rank of a slave

the slave sends to the server:
@code
PUT /rank/<jobid>/<rank>
content-size: 0
@endcode

and, for the rank 0, the server forwards to the controller:
@code
STARTED /job/<jobid>
content-size: 0
@endcode

The controller has a default rank value of -1 (dtkDistributedMessage::CONTROLLER_RANK), the server -2
(dtkDistributedMessage::SERVER_RANK), and when the controller needs to
separate commands from data communications (the dtkComposerNodeRemote
is using this), it should use -3 (dtkDistributedMessage::CONTROLLER_RUN_RANK).

\subsection data send data

the slave or the controller sends:
@code
POST /data/<jobid>/<rank_dest>
content-size: <size>
content-type: json|text|binary
<data>
@endcode

and the server forwards to  <rank_dest>:
@code
POST /data/<jobid>
x-forwarded-for: <rank_src>
content-size: 0
content-type: json|text|binary
<data>
@endcode




\section format JSON format description

\subsection jstatus status format

When a status request is sent to the dtkDistributedServerManager, the
output format is :

@code
             {  "version": "<xx.yy>",
                "jobs" : [ { "id" : "<job_id>",
                            "queue" : "<queuename>",
                            "queue_time" : <epoch>,
                            "resources" : { "cores" : <XX>, "nodes" : <yy> },
                            "start_time" : "",
                            "state" : "running|queued|suspended|blocked|exiting|scheduled|unknown",
                            "username" : "<username>",
                            "walltime" : "hh:mm:ss" }
                          , ... ],
                "nodes" : [ { "cores" : [ { "id" : <id0> [, "job" : "<jobid>"]}, ...]
                             "cores_busy" : <ncores_busy>,
                             "cpus" : <ncpus>,
                             "gpus" : <ngpus>,
                             "gpus_busy" : <ngpus_busy>,
                             "name" : "<nodename>",
                             "properties" : { "cpu_arch" : "<x86_64|x86>",
                                              "cpu_model" : "<xeon|opteron>",
                                              "ethernet" : "<1G|10G>",
                                              "properties": {{"key": "value"}, ...},
                                              },
                              "state" : "free|busy|down|standby|absent" }
                          , ... ],
              }
@endcode

example:
@code
             {  "version": "1.0",
                "jobs" : [ { "id" : "6447081",
                            "queue" : "seqextralong",
                            "queue_time" : "1316525900",
                            "resources" : { "cores" : "1", "nodes" : "1" },
                            "start_time" : "",
                            "state" : "running",
                            "username" : "nniclaus",
                            "walltime" : "144:00:00" }, ...],
                "nodes" : [ { "cores" : [ { "id" : 80, "job" : "6447081"},
                                          { "id" : 81 }, { "id" : 82 }, { "id" : 83 },
                                          { "id" : 84 }, { "id" : 85 }, { "id" : 86 },
                                          { "id" : 87 }, { "id" : 88 }]
                             "cores_busy" : 0,
                             "cpus" : "2",
                             "gpus" : "2",
                             "gpus_busy" : 0,
                             "name" : "nefgpu01.inria.fr",
                             "properties" : { "cpu_arch" : "x86_64",
                                              "cpu_model" : "opteron",
                                              "ethernet" : "1G",
                                              "gpu_arch" : "nvidia-1.3",
                                              "gpu_model" : "T10",
                                              "infiniband" : "QDR" },
                              "state" : "free" }, ...]
              }
@endcode


\subsection job

For job submission, the format is:

@code
             {  "resources": {"nodes": 0..N, "cores": 1..M },
                "properties": {{"key": "value"}, ...},
                "walltime": "hh:mm:ss",
                "script": "script_path" | "application": "app_args",
                "queue": "queuename";
                "options": "string"
              }
@endcode


 */
